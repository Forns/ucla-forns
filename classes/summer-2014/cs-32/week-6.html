
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

  <head>
    <title>Andrew Forney - UCLA CS</title>
    <link href="../../../css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="../../../css/magic-bootstrap.css" rel="stylesheet" type="text/css">
    <link href="../../../css/main.css" rel="stylesheet" type="text/css">
    <script src="../../../js/lib/jquery-2.0.3.min.js"></script>
    <script src="../../../js/lib/bootstrap.min.js"></script>
    <script src="../../../js/lib/expanding.js"></script>
    <script src="../../../js/lib/chart.min.js"></script>
    <script src="../../../js/display/general/general-display.js"></script>
    <script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js"></script>
  </head>
  
  <body data-spy="scroll" data-target="#scrollspy">
    
    <!-- BEGIN WRAP -->
    <div id="wrap">
      
      <!-- BEGIN NAVIGATION -->
      <nav class='navbar navbar-default' role='navigation'>
        <div class='nav-accent'></div>
        <div class='container'>
          <div class='row'>
            <div class='col-md-12'>
              <div class='navbar-header'>
                <button class='navbar-toggle' type='button' data-toggle='collapse' data-target='.navbar-main-collapse'>
                  <span class='sr-only'>Toggle Navigation</span>
                  <span class='icon-bar'></span>
                  <span class='icon-bar'></span>
                  <span class='icon-bar'></span>
                </button>
                <a class='navbar-brand' href='/~forns/'>
                  <span id='brand-text'>
                    Andrew Forney
                  </span>
                </a>
              </div>
              
              <div id='nav-main' class='collapse navbar-collapse navbar-main-collapse'>
                <ul class='nav navbar-nav navbar-right'>
                  
                  <li>
                    <a href='/~forns/about.html'>
                      <div class='text-center'>
                        <span class='glyphicon glyphicon-user'></span>
                      </div>
                      <p class='text-center'>About</p>
                    </a>
                  </li>
                  
                  <li class='active'>
                    <a href='/~forns/classes.html'>
                      <div class='text-center'>
                        <span class='glyphicon glyphicon-book'></span>
                      </div>
                      <p class='text-center'>Classes</p>
                    </a>
                  </li>
                  
                  <li>
                    <a href='/~forns/contact.html'>
                      <div class='text-center'>
                        <span class='glyphicon glyphicon-comment'></span>
                      </div>
                      <p class='text-center'>Contact</p>
                    </a>
                  </li>
                  
                  <li>
                    <a href='/~forns/publications.html'>
                      <div class='text-center'>
                        <span class='glyphicon glyphicon-file'></span>
                      </div>
                      <p class='text-center'>Publications</p>
                    </a>
                  </li>
                  
                </ul>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <!-- END NAVIGATION -->
      
      <!-- BEGIN MAIN CONTENT -->
      <div id="main-content" class="container">
        <div class="row">
          
          <!-- BEGIN SCROLLSPY -->
          <div class='col-md-2 hidden-sm hidden-xs'>
            <div class="bs-sidebar hidden-print affix" role="complementary">
              <ul id='scrollspy' class="nav bs-sidenav">
              </ul>
            </div>
          </div>
          <!-- END SCROLLSPY -->
          
          <!-- BEGIN PRESENTATION CONTENT -->
          <div class='col-md-10 presentation-content' role='main'>
            
            <ol class="breadcrumb hidden-print">
              <li><a href="../../../classes.html">Classes</a></li>
              <li><a href="./cs-32.html">Winter14 CS32</a></li>
              <li class="active">Week 9</li>
            </ol>
            
            
            <div id='review' class='scrollspy-element' scrollspy-title='Review'></div>
            <h1>Practice &amp; Questions from Last Week</h1>
            <div>
              <p>Last class, someone asked a good question:</p>
              <p><strong>Q:</strong> What makes quicksort preferred to mergesort? What are the circumstances where we would use one over the other?</p>
              <p>A: As it turns out, quicksort wins on a variety of metrics, though its advantage is not clear cut in all circumstances. Here are its main benefits:</p>
              <ul class='indent-1'>
                <li><p>Quicksort requires less space than does mergesort since it does not need to keep track of each sublist after it has recombined. Mergesort, on the other hand, must keep track of
                  each of its sublists throughout the algorithm until it has recombined into the complete list.</p></li>
                <li><p>Avoiding quicksort's worst case scenario O(n^2) is not particularly difficult with empowered (read: smartly chosen through some heuristic) pivot choices, though isn't guaranteed.</p></li>
                <li><p>Because quicksort eventually creates small sublists that are semi-sorted, it is sometimes more efficient to quicksort down to sublists of some small size and then sort those smaller lists
                  with an algorithm like insertion sort or heapsort.</p></li>
              </ul>
              <br/>
              <p>That said, there are also arguments for mergesort:</p>
              <ul class='indent-1'>
                <li><p>Although quicksort has a smaller hidden constant of proportionality (fewer comparisons and operations), its nondeterministic nature means that when you must *absolutely guarantee* 
                  n*log(n) complexity, mergesort is the way to go.</p></li>
                <li><p>Malicious users / programmers may be able to construct input to your code on which quicksort devolves to O(n^2) (think: what would they do? how might you fix this?).</p></li>
              </ul>
              <br/>
              <p>So there you have it... in summary:</p>
              <p><strong>tl;dr: Quicksort is faster on average, but if you need to guarantee linearithmic time complexity, use mergesort.</strong></p>
              
              <br/>
              <h3>Complexity Review</h3>
              
              <p>There were a significant number of questions regarding time complexity in the logarithmic case.</p>
              <p>Since tree algorithms generally involve some flavor of a log complexity, let's review some algorithms now...</p>
              <p class='definition'>
                A rule of thumb for logarithm complexity is when you're omitting or ignoring some number of input elements with every step that is proportional to the log of the size of the input.
              </p>
              <p>Often, this is manifest in divide-and-conquer algorithms, but sometimes it's simpler than that... that for example the following:</p>
              <p class='example'>What is the time complexity of the following function?</p>
<pre class='prettyprint'>
  void someFunc (vector&lt;int&gt; v) {
      for (int i = 1; i &lt; v.size(); i *= 2) {
          cout &lt;&lt; v[i] &lt;&lt; endl;
      }
  }
</pre>
              <br/>
              <p>We also know that some algorithms can have logarithmic components that rely on other components of the algorithm, and vice versa...</p>
              <p class='example'>What is the time complexity of the following function?</p>
<pre class='prettyprint'>
  void someFunc (vector&lt;int&gt; v) {
      for (int i = 0; i &lt; v.size(); i++) {
          for (int j = i; j &gt; 0; j /= 2) {
              if (v[j] == v[i]) {
                  cout &lt;&lt; v[i] &lt;&lt; endl;
              }
          }
      }
  }
</pre>
              <br/>
              <p>You should also be aware that big-O complexity need not be reliant upon a single input; you can have complexities in terms of multiple inputs as well!</p>
              <p class='example'>What is the time complexity of the following function?</p>
<pre class='prettyprint'>
  // [!] Consider N = v1.size() and M = v2.size()
  void someFunc (vector&lt;int&gt; v1, vector&lt;int&gt; v2) {
      for (int i = 0; i &lt; v1.size(); i++) {
          for (int j = 0; j &gt; v2.size(); j += 2) {
              if (v1[i] == v2[j]) {
                  cout &lt;&lt; v1[i] &lt;&lt; endl;
              }
          }
      }
  }
</pre>
              <br/>
              <p>Lastly, let's remember our tree algorithm complexities...</p>
              <p class='example'>What is the time complexity of the following function?</p>
<pre class='prettyprint'>
  // [!] Consider N = v1.size() and M = s.size()
  void someFunc (vector&lt;int&gt; v1, set&lt;int&gt; s) {
      for (int i = 0; i &lt; v1.size(); i++) {
          if (s.find(v[i]) != s.end()) {
              cout &lt;&lt; v1[i] &lt;&lt; endl;
          }
      }
  }
</pre>
              <br/>
              <h3>Binary Tree Review</h3>
              <p class='example'>Continuing with some warmup... remind me what postorder traversal is again? What's the postorder traversal of this tree?</p>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/winter-2014/cs-32/week-8/trees-7.PNG">
              </div>
              <p class='definition'>[!] Interesting property about postorder traversal... what happens when I remove each Node found in postorder traversal, in the order in which I visit them?</p>
            </div>
            <hr/>
            
            <br/>
            <div id='bintreeAlgorithms' class='scrollspy-element' scrollspy-title='BinTree Algorithms'></div>
            <h1>Binary Tree Algorithms</h1>
            <div>
              <p>We've seen some traversal algorithms for binary trees, but let's look at a couple extra for practice.</p>
              <p>Below, I've gotten us started with a Binary Tree class, as well as a new way to insert Nodes with a given path to an empty space.</p>
<pre class='prettyprint'>
  struct BinTree {
      // BinTreeNode struct internal
      // to the BinTree
      struct BinTreeNode {
          int data;
          BinTreeNode* left;
          BinTreeNode* right;
          BinTreeNode(int d) {
              data = d;
              left = nullptr;
              right = nullptr;
          }
      };
  
      // Root just points to a single
      // BinTreeNode
      BinTreeNode* root;
  
      BinTree() {
          root = nullptr;
      }
      ~BinTree() {}; // TODO!
      void insertAt (int i, string path);
  };
  
  // Creates a new node with the given data member
  // if input string p specifies a path in terms of
  // L and R children to follow to an empty spot in
  // the tree
  // The path p will look like some string of "LRL"
  void BinTree::insertAt (int data, string p) {
      BinTreeNode* b = root;
      BinTreeNode* last = nullptr;
      int i = 0;
  
      // First, we'll go through our desired path
      // of insertion
      while (i &lt; p.length()) {
          // If we hit the nullptr before we're
          // done, just break out of the loop
          if (b == nullptr) {
              break;
          }
          // Keep track of our parent node...
          last = b;
          // ...then move on to the path's desired
          // child
          b = (p[i] == 'L') ? b-&gt;left : b-&gt;right;
          i++;
      }
  
      // If we followed a path the length of
      // our desired path, then we have a valid
      // insertion; otherwise the path was
      // mis-specified
      if (i == p.length()) {
          // If there's already a node there,
          // bad path, so we'll just return
          if (b != nullptr) {
              return;
          }
          // Otherwise, there's an opening, so
          // we'll make a new node at b
          b = new BinTreeNode(data);
          // If there's nothing in the tree yet,
          // then b is our root!
          if (root == nullptr) {
              root = b;
          }
          // If we have a parent node to add
          // the child to, update its left or
          // right pointer
          if (last != nullptr) {
              if (p[i - 1] == 'L') {
                  last-&gt;left = b;
              } else {
                  last-&gt;right = b;
              }
          }
      }
  }
</pre>
              <p>So, if I wanted to add Nodes to my tree, I would simply say:</p>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/winter-2014/cs-32/week-9/btree-0.png' />
              </div>
              <br/>
              <p>So, now I can recreate this tree in my BinaryTree class via:</p>
<pre class='prettyprint'>
  int main () {
      BinTree bt;
      bt.insertAt(14, "");
      bt.insertAt(10, "L");
      bt.insertAt(8, "LL");
      bt.insertAt(11, "LR");
      bt.insertAt(15, "R");
  }
</pre>
              <br/>
              <p>Neat! Now let's look at making some of our own functions...</p>
              <p>First, let's have a way to print out our tree; we'll print out each subtree as enclosed within parentheses, like so:</p>
<pre class='prettyprint'>
  int main () {
      BinTree bt;
      
      bt.insertAt(14, "");
      // prints: (14)
      printByClosure(bt.root);
      cout &lt;&lt; endl;
        
      bt.insertAt(10, "L");
      // prints: ((10)14)
      printByClosure(bt.root);
      cout &lt;&lt; endl;
        
      bt.insertAt(8, "LL");
      // prints: (((8)10)14)
      printByClosure(bt.root);
      cout &lt;&lt; endl;
        
      bt.insertAt(11, "LR");
      // prints: (((8)10(11))14)
      printByClosure(bt.root);
      cout &lt;&lt; endl;
        
      bt.insertAt(15, "R");
      // prints: (((8)10(11))14(15))
      printByClosure(bt.root);
      cout &lt;&lt; endl;
  }
</pre>
              <br/>
              <p>Complete the function shell for printByClosure below:</p>
<pre class='prettyprint'>
  void printByClosure (BinTree::BinTreeNode* b) {
      // [!] Base case
      if ( ??? ) {
          ???
      }
  
      // [!] Otherwise, starting a new
      // closure, so print out...
      cout &lt;&lt; ???;
  
      // [!] Perform some form of traversal
      // here... which one will give us the
      // desired output?
      
      // [!] Ending our closure, so print...
      cout &lt;&lt; ???;
  }
</pre>
              <br/>
              <p>Let's do something &quot;fun&quot;... why don't we create a function that turns our tree into a mirror image of itself?</p>
<pre class='prettyprint'>
  int main () {
      BinTree bt;
      bt.insertAt(14, "");
      bt.insertAt(10, "L");
      bt.insertAt(18, "R");
      printByClosure(bt.root);
      cout &lt;&lt; endl;
      // Was ((10)14(18)),
      // Now ((18)14(10))
      mirror(bt.root);
      printByClosure(bt.root);
      cout &lt;&lt; endl;
  
      bt.insertAt(17, "LR");
      printByClosure(bt.root);
      cout &lt;&lt; endl;
      // Was ((18(17))14(10)),
      // Now ((10)14((17)18))
      mirror(bt.root);
      printByClosure(bt.root);
      cout &lt;&lt; endl;
  }
</pre>
              <br/>
              <p class='example'>Complete the function shell for mirror, below:</p>
<pre class='prettyprint'>
  void mirror (BinTree::BinTreeNode* b) {
      // [!] Base Case
      if ( ??? ) {
          return;
      }
    
    // Create a temp holder for our swap
      BinTree::BinTreeNode* temp;
    
    // [!] Perform some order of traversal
    // to do the swap... which one?
      ???
    
    // [!] Swap the current node's left
    // and right with the temp, saving
    // one into temp first
      ???
  }
  // ^ Example credit to Stanford's tree examples
  // (listed later)
</pre>
              <br/>
              <p>I'll have some more examples using this class on the practice final...</p>
            </div>
            <hr/>
            
            
            <br/>
            <div id='bstAlgorithms' class='scrollspy-element' scrollspy-title='BST Algorithms'></div>
            <h1>Binary Search Tree Algorithms</h1>
            <div>
              <p>Perhaps more interesting than simply binary trees, are Binary Search Trees, which as we recall, adhere to the additional constraints that:</p>
              <ul class='indent-1'>
                <li><p>No node may have more than 2 children</p></li>
                <li><p>All nodes to the left of a given node must be less than that node, and all nodes to the right of a given node must be less than (or equal) to it</p></li>
              </ul>
              <br/>
              <p>Here's a simple binary search tree class skeleton:</p>
              <br/>
<pre class='prettyprint'>
  struct BST {
      // BSTNode struct internal
      // to the BST
      struct BSTNode {
          int data;
          BSTNode* left;
          BSTNode* right;
          BSTNode(int d) {
              data = d;
              left = nullptr;
              right = nullptr;
          }
      };
      
      // Root just points to a single
      // BSTNode
      BSTNode* root;
      
      BST() {
          root = nullptr;
      }
      ~BST() {}; // TODO!
      void insert (int i); // TODO!
      void clear(BSTNode* subtree); // TODO!
  };
</pre>
              <br/>
              <p>Now, the insertion algorithm isn't too bad... let's try to code an iterative version:</p>
              <br/>
              <p class='example'>Complete the BST insert function started below:</p>
<pre class='prettyprint'>
  // Creates a new node with the given data member
  // in the BST
  void BST::insert (int data) {
      BSTNode* b = root;
      
      // Base case: tree is empty
      if ( ??? ) {
          ???
          return;
      }
      
      // Otherwise, find its proper position
      while (true) {
          // Case: Data is less than current node
          if (data &lt; b-&gt;data) {
              // If there's already a node left...
              if (b-&gt;left) {
                  // Then continue down the tree
                  ???
              
              // Otherwise, no node to left, so insert:
              } else {
                  ???
                  return;
              }
              
          // Case: Data is greater than / equal to node
          } else {
              if (b-&gt;right) {
                  ???
              } else {
                  ???
                  return;
              }
          }
      }
  }
</pre>
              <br/>
              <p>Cool, nice and simple... we can confirm that everything's working with the following main function:</p>
              <br/>
<pre class='prettyprint'>
  int main () {
      BST bs; // hehe... bs
      bs.insert(5);
      bs.insert(4);
      bs.insert(6);
      bs.insert(3);
      
      cout &lt;&lt; bs.root-&gt;data &lt;&lt; endl;             // 5
      cout &lt;&lt; bs.root-&gt;left-&gt;data &lt;&lt; endl;       // 4
      cout &lt;&lt; bs.root-&gt;right-&gt;data &lt;&lt; endl;      // 6
      cout &lt;&lt; bs.root-&gt;left-&gt;left-&gt;data &lt;&lt; endl; // 3
  }
</pre>
              <br/>
              <p>Here's a good practice problem... how might we code the destructor of our BST? Hint: think about traversal tactics:</p>
              <p class='example'>Complete the destructor code skeleton for our BST class below:</p>
              <br/>
<pre class='prettyprint'>
  // Clears all nodes, making sure to
  // deallocate appropriately
  void BST::clear(BSTNode* subtree) {
      // Base case: reached an ending
      if ( ??? ) {
          return;
      }
      
      // Otherwise, traverse and delete:
      ???
      ???
      
      // [!] Printout for example before
      // deleting:
      cout &lt;&lt; subtree-&gt;data &lt;&lt; endl;
      ???
  }
  
  // Destructor properly calls clear
  BST::~BST() {
      clear(root);
  }
</pre>
            </div>
            <hr/>
            
            
            <br/>
            <div id='treeBalancing' class='scrollspy-element' scrollspy-title='Tree Balancing'></div>
            <h1>Balancing Binary Search Trees</h1>
            <div>
              <p>
                Now, we remember that binary search trees are great because, for some extra cost during their construction (average O(log(n)), worst O(n)), we can reduce search operations 
                (in the average case) to about O(log(n)) time complexity.
              </p>
              <p class='question' name='btree-q0'>Say I'm inserting ints into a binary search tree. What property of this input list of ints will cause insertion to take O(n) time?</p>
              <p class='answer' name='btree-q0'>When the insertions are done one at a time and arrive in sorted order.</p>
              <p class='definition'>You can test out insertion into a binary tree <a href='http://www.cs.jhu.edu/~goodrich/dsa/trees/btree.html' target='_blank'>here (click me)</a></p>
              <br/>
              <p>Well, as it turned out, that worst case insertion was problematic... and the more linear, and less tree-like binary search trees became, the less efficient their search became too!</p>
              <p>So the eggheads of yore considered making an algorithm that would keep the tree balanced such that any insertion won't make the tree become too linear.</p>
              <p>There are a variety of different ways to keep trees balanced and maintain the log(n) search guarantee for binary search trees; we'll examine a couple now.</p>
              <br/>
              <h3>AVL Trees</h3>
              <p class='definition'>AVL trees have 1 property in addition to those of binary search trees: the heights (depths) of any two of a given node's subtrees must differ by *at most* 1.</p>
              <p>This enforced property makes sure that the depth of any subtree never becomes too linear, which would degrade the efficiency of search and further insertions.</p>
              <p>This balancing act takes O(log(n)) time, which means that, upon insertion of any new value, we get O(log(n) + log(n)) = O(log(n)) time; a greater overhead, but same complexity class.</p>
              <br/>
              <ol class='indent-1'>
                <li><p>Firstly, we keep track of a &quot;balance factor&quot; at each node which is equal to: <code class='prettyprint'>balance = height(left_subtree) - height(right_subtree)</code></p></li>
                <li><p>A tree is out of balance if its balance factor is greater than or equal to 2, or less than or equal to -2.</p></li>
                <li><p>If a tree is out of balance, then we use the following balancing algorithm:</p></li>
              </ol>
<pre class='prettyprint'>
  // Code skeleton for C++, edited from Wikipedia :)
  if (balance_factor(L) == 2) { // The left subtree
      Node* P = left_child(L);
      if (balance_factor(P) == -1) { // The "Left Right Case"
          rotate_left(P); // Reduce to "Left Left Case"
      }
      // The Left Left Case
      rotate_right(L);
      
  } else { // balance_factor(L) == -2, the right subtree
      Node* P=right_child(L);
      if (balance_factor(P) == 1) { //The "Right Left Case"
         rotate_right(P); // Reduce to "Right Right Case"
      }
      // The Right Right Case
      rotate_left(L);
  }
</pre>
              <br/>
              <p>So what does it mean to &quot;rotate&quot; a tree, you might ask?</p>
              <p class='definition'>A rotation promotes a child node to the parent, and demotes the parent to a child node depending on the direction of the rotation. Subtree structures are maintained.</p>
              <div class='text-center fit-pres'>
                <a href='http://en.wikipedia.org/wiki/AVL_tree' target='_blank'>
                  <img src='../../../assets/images/winter-2014/cs-32/week-9/tree-rotation.png' />
                  <br/>
                  <small>(credit to Wiki for image)</small>
                </a>
              </div>
              <br/>
              <p>Above, a right / clockwise rotation would start at the right image and finish with the left image.</p>
              <p>Similarly, a left / counter-clockwise rotation would start at the left image and finish with the right image.</p>
              <p>Notice that the subtree structures are maintained with each rotation.</p>
              <div class='question' name='rotation-q0'><p>What would a left rotation of the 10 node look like in the following tree?</p>
                <div class='text-center fit-pres'>
                  <img src='../../../assets/images/winter-2014/cs-32/week-9/tree-rotation-1.png' />
                </div>
              </div>
              <div class='answer' name='rotation-q0'>
                <div class='text-center fit-pres'>
                  <img src='../../../assets/images/winter-2014/cs-32/week-9/tree-rotation-2.png' />
                </div>
              </div>
              <br/>
              <p>Now that we have the basics of rotation down, let's look at an example inserting into an AVL tree:</p>
              <br/>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/summer-2014/cs-32/week-6/av-ex-0.png' />
              </div>
              <br/>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/summer-2014/cs-32/week-6/av-ex-1.png' />
              </div>
              <br/>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/summer-2014/cs-32/week-6/av-ex-2.png' />
              </div>
              <br/>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/summer-2014/cs-32/week-6/av-ex-3.png' />
              </div>
              <br/>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/summer-2014/cs-32/week-6/av-ex-4.png' />
              </div>
              <br/>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/summer-2014/cs-32/week-6/av-ex-5.png' />
              </div>
              <br/>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/summer-2014/cs-32/week-6/av-ex-6.png' />
              </div>
              <br/>
              <p>Neat!</p>
              <p>So remember: AVL trees balance subtree heights, not necessarily just the number of nodes per subtree!</p>
              <br/>
              <p class='definition'>Let's examine a visualization <a href='http://www.cs.jhu.edu/~goodrich/dsa/trees/avltree.html' target='_blank'>here (click me)</a></p>
              
              <br/>
              <h3>Red-Black Trees</h3>
              <p>
                So, the one problem with AVL trees is that with a lot of insertions, you'll have to keep performing the balancing overhead any time a branch becomes 2 depths or more greater than a parent.
              </p>
              <p>
                Red-Black Trees said, &quot;Hey, let's not do all of this rebalancing nonsense all the time; everything's chill until the path from the root to the farthest leaf is no more than twice
                the distance from the root to the closest leaf.&quot;
              </p>
              <p>So, without diving deep into how it rebalances when this distance is exceeded, let's just look at some properties of red-black trees lifted from wikipedia:</p>
              <ul class='indent-1'>
                <li><p>A node is &quot;painted&quot; either red or black</p></li>
                <li><p>The root is black</p></li>
                <li><p>Every red node must have two black child nodes</p></li>
                <li><p>Every path from a given node to any of its descendant leaves contains the same number of black nodes.</p></li>
              </ul>
              <p>What we end up with is a binary search tree that still ensures O(log(n)) search without the need to so frequently rebalance.</p>
              <p class='definition'>Let's examine a visualization <a href='http://www.ece.uc.edu/~franco/C321/html/RedBlack/redblack.html' target='_blank'>here (click me)</a></p>
            </div>
            <hr/>
              
            
            <br/>
            <div id='STLSetMap' class='scrollspy-element' scrollspy-title='STL Set &amp; Map'></div>
            <h1>STL Set &amp; Map</h1>
            <div>
              <p>Let's take a whirlwind tour through two STL collections: the set and the map</p>
              
              <br/>
              <h3>#include &lt;set&gt;</h3>
              <p class='definition'><strong>Sets</strong> are simply a collection of items of the given templated type stored in a binary search tree.</p>
              <p>Here's an example of some common operations with sets:</p>
<pre class='prettyprint'>
  int main () {
      set&lt;int&gt; s;
  
      // Inserting values into set
      s.insert(5);
      s.insert(20);
      s.insert(2);
  
      // You can erase values from the set
      s.erase(2);
      s.insert(3);
  
      // You can define iterators
      // [!] This is a binary search tree,
      // what will get printed out?
      set&lt;int&gt;::iterator sit = s.begin();
      while (sit != s.end()) {
          cout &lt;&lt; *sit++ &lt;&lt; endl;
      }
  
      // Get the size of the set
      cout &lt;&lt; "size: " &lt;&lt; s.size() &lt;&lt; endl;
  
      // Clear the set
      s.clear();
  }
</pre>
              <br/>
              <h3>#include &lt;map&gt;</h3>
              <p class='definition'><strong>Maps</strong> are simply a collection of key/value pairs (associations) of the given templated types stored in a binary search tree.</p>
              <p>These are very similar to your MultiMap for homework!</p>
<pre class='prettyprint'>
  int main () {
      map&lt;string, int&gt; m;
  
      // Inserting values into map
      m["look"] = 3;
      m["at"] = 20;
      m["me"] = 10;
      // [!] Note! Unlike vectors, in which the
      // bracket operator is undefined when the
      // index is out of range, this insertion
      // method is OK for keys that haven't been
      // set yet
  
      // You can erase values from the map
      m.erase("look");
      m["yo"] = 15;
  
      // You can update existing values
      m["me"] = 12;
  
      // You can define iterators
      // [!] This is a binary search tree,
      // what will get printed out?
      map&lt;string, int&gt;::iterator mit = m.begin();
      while (mit != m.end()) {
          // [!] Keys in iterators are stored in a
          // "first" field; values in a "second" field
          cout &lt;&lt; mit-&gt;first &lt;&lt; ": " &lt;&lt; mit-&gt;second &lt;&lt; endl;
          mit++;
      }
  
      // Get the size of the map
      cout &lt;&lt; "size: " &lt;&lt; m.size() &lt;&lt; endl;
  
      // Clear the map
      m.clear();
  }
</pre>
            </div>
            <hr/>
            
            
            <br/>
            <div id='23trees' class='scrollspy-element' scrollspy-title='2-3 Trees'></div>
            <h1>2-3 Trees</h1>
            <div>
              <p>Because 1 tree wasn't enough!</p>
              <p>2-3 trees belong to a class of data structures called B-Trees:</p>
              <br/>
              <p class='definition'><strong>B-Trees</strong> are generalizations of binary search trees that, while accomplishing access, insertion, and deletion in logarithmic time, allow for nodes with 
                more than 2 children each.</p>
              <br/>
              <p>So why do we care about generalizations of binary search trees?</p>
              <p>As it turns out, we can improve somewhat on the constant of proportionality with our logarithmic time complexity of insertion, lookup, and other operations by saving some rebalancing.</p>
              <p>The chief properties of a 2-3 tree that allow us to do that are the following:</p>
              <br/>
              <div class='definition'>
                <p>A <strong>2-3 Tree</strong> possesses two types of nodes:</p>
                <br/>
                <ul class='indent-1'>
                  <li><p>A <strong>2-node</strong> contains 1 data element in its node, and has at most 2 children; nodes in its left subtree are less than it, and nodes in its right are greater than
                    (or equal to) it.</p></li>
                  <li><p>A <strong>3-node</strong> contains 2 data elements in its node (a left and a right value), and has at most 3 children; nodes in its left subtree are less than the left value,
                    nodes in its middle subtree are between the left and the right, and nodes in its right subtree are greater than (or equal to) the right value.</p></li>
                </ul>
              </div>
              <br/>
              <p>Here's an example of a 2-3 Tree and the types of nodes they contain:</p>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/2-3-tree.png">
              </div>
              
              <br/>
              <h3>Insertion</h3>
              <p>So how do we actually end up with a 2-3 tree? Well, the algorithm can be boiled down to the following pseudocode:</p>
              <br/>
<pre class='prettyprint'>
  // insert algorithm:
  
  if the tree is empty, insert a 2-Node with the value
  else, traverse the tree to find where the value goes
      once you find the node
          if that node is a 2-Node
              add the value to make it a 3-Node
          else
              promote the middle value to the parent
  
              
  // promote algorithm:
  
  if the parent is a 2-Node
      add promoted value as 2nd value, making it a 3-Node
      children placed according to relation to parent values
  if the parent is a 3-Node
      promote the middle value of those three (recursive call)
  if no parent
      promote the middle value to its own 2-Node
      split the remaining 2 values into their own 2-Nodes
      children placed according to relation to new 2-Nodes
</pre>
              <br/>
              <p>Whew! That looks complicated, but let's look at a simple example, step by step:</p>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-0.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-1.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-2.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-3.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-4.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-5.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-6.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-7.png">
              </div>
              <br/>
              <div class="text-center fit-pres">
                <img src="../../../assets/images/summer-2014/cs-32/week-6/23-ex-8.png">
              </div>
              <br/>
              <p>And there you have it!</p>
              <p>Deletion is substantively more complicated and won't be detailed in this lecture.</p>
              <p>There are many articles and videos on the topic that a simple Google search will demonstrate, but for which we simply don't have time in discussion.</p>
            </div>
            <hr/>
            
            
            <br/>
            <div id='hash' class='scrollspy-element' scrollspy-title='Hash Tables'></div>
            <h1>Hash Tables</h1>
            <div>
              <p>If you're me and you're looking for something at a supermarket, you'll probably wander aimlessly, looking at each row until you find it.</p>
              <p>Yet, if you ask a store employee, you'll find that, for the most part, they'll know exactly which row your item is in without having to look!</p>
              <p>(I, of course, never ask because male ego, etc.)</p>
              <p>Now to bring the analogy home, it'd be nice if we had some &quot;store employee&quot; with our data structure collections that could tell tell us where to look for a query.</p>
              <p class='definition'>
                A <strong>hash table</strong> provides us with a means of storing data structures into certain buckets such that we can consult a hash function to determine where a particular item
                should go (for insertion) or where it might already live (for search).
              </p>
              <p class='definition'>For a given value to store or a query to a hash table, the <strong>hash function</strong> tells us which bucket to store it in / look in.</p>
              <br/>
              <p>So, to unpack those definitions a bit:</p>
              <ul class='indent-1'>
                <li><p>The hash table is like the grocery store in our analogy.</p></li>
                <li><p>The hash function is like the employee that we ask which aisle a particular item is in that we're looking for.</p></li>
                <li><p>The hash buckets are like the aisles of the grocery store.</p></li>
              </ul>
              <p>So why is this useful?</p>
              <p>
                Well, if we had about 1000 items we needed to store, and 1000 buckets in which to store them, then assuming we chose a good hash function to evenly divide up the items into buckets, we
                could perform insertion and search in near constant time! O(1), wow!
              </p>
              <p>
                This is because we reduce the possible set of matches down to only those contents of a particular bucket, which is, if the items are uniformly distributed, going to be very small
                compared to the original collection.
              </p>
              <p>Constant time is the gold standard of data structures and you're saying it's possible?! Let us learn of these wonderous devices by building a simple one of our own.</p>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/winter-2014/cs-32/week-10/hash-0.png' />
              </div>
              
              <br/>
              <h3>The Hash Table</h3>
              <p>Let's begin by designing our hash table.</p>
              <p class='definition'>A hash table needs buckets that are accessible by index.</p>
              <br/>
              <p class='question' name='hash-q0'>Why do our hash buckets need to be accessible by index, and what data structure what you suggest to use for our buckets?</p>
              <p class='answer' name='hash-q0'>
                If we want constant time lookup and search, we'll need random access or else we'd have to traverse some number of Node-like objects to reach our goal bucket. Also, it's convenient
                for a hash function to only hash items to integer ids. So, for the purposes of this example, we'll use a vector.
              </p>
              <br/>
              <p>OK, let's define our HashTable class below:</p>
<pre class='prettyprint'>
  template &lt;typename T&gt;
  class HashTable {
      private:
          // LOL "BUCKET LIST"
          vector&lt;list&lt;T&gt;&gt; buckets;
  };
</pre>
              <br/>
              <p>Well that's dull so far...</p>
              <p>Note we use (for this example) a vector for the buckets (enable random access) and lists for the individual bucket contents.</p>
              <p>We'll template our HashTable so we can store different stuff.</p>
              <p>Now, for the constructor, how many buckets do we want to start it off with?</p>
              <p class='question' name='hash-q1'>What is the tradeoff for having more or fewer buckets in our hash table?</p>
              <p class='answer' name='hash-q1'>
                More buckets means that fewer items will be in each bucket (if our hash function performs a uniform distribution of the items) at the cost of having to take up more space in memory.
              </p>
              <br/>
              <p>So, let's start off at, say, 1,000 buckets.</p>
<pre class='prettyprint'>
  template &lt;typename T&gt;
  class HashTable {
      private:
          int MAX_BUCKETS;
          vector&lt;list&lt;T&gt;&gt; buckets;
      public:
          HashTable (): MAX_BUCKETS(1000) {
              // Start off the buckets with MAX_BUCKETS
              buckets.resize(MAX_BUCKETS);
          }
  };
</pre>
              <br/>
              <p>Alright, the stage is set... let's talk about hash functions.</p>
              
              <br/>
              <h3>Hash Functions</h3>
              <p>Hash functions act as our &quot;oracles&quot; that tell us which bucket a particular item should go in.</p>
              <p>They receive as input whatever item we're trying to store or lookup and output an int index somewhere between [0, b), where b is the number of buckets.</p>
              <p>There are some properties of hash functions we need to satisfy...</p>
              <p class='definition'>Hash functions need to be fast!</p>
              <br/>
              <p>
                If our hash function crawls wikipedia for articles on obscure topics, converts every character in those articles to its character code equivalent, adds them, and then mods them by the biggest
                prime number that will fit things neatly into our buckets... we're probably gonna have a bad time (literally).
              </p>
              <p>So, we want something that's simple, quick, and satisfies this other property:</p>
              <p class='definition'>Hash functions need to evenly distribute our items into buckets.</p>
              <br/>
              <p>If our buckets start to hold too many items, then the hash table will be pretty useless... we'll just have a linear search internal to our lists!</p>
              <p>So, we need to determine a way to, pretty uniquely, determine what item goes into what bucket!</p>
              <p class='definition'>When a hash function maps inputs to the same bucket, we call that a <strong>collision</strong>.</p>
              <br/>
              <p>Generally, we want to avoid collisions because they hurt.</p>
              <p>But seriously, the more collisions we have, the more our complexity suffers because it means we have to find values within our lists.</p>
              <p>A last property our hash functions should have:</p>
              <p class='definition'>
                Hash functions should be <strong>deterministic</strong>, meaning that if value A maps to bucket B in one call to our hash function, then it should map to bucket B in future calls as well.
              </p>
              <br/>
              <p>Keeping this in mind, let's propose a couple of hash functions for our HashTable.</p>
              <br/>
              <p class='example'>Judge whether or not the following is a good hash function:</p>
<pre class='prettyprint'>
  unsigned int hash (int toHash) {
      return toHash % 2;
  }
</pre>
              <br/>
              <p class='example'>Judge whether or not the following is a good hash function:</p>
<pre class='prettyprint'>
  unsigned int hash (string toHash) {
      unsigned int result = 0;
      for (int i = 0; i &lt; toHash.length(); i++) {
          result += toHash[i];
      }
      return result % rand();
  }
</pre>
              <br/>
              <p class='example'>Judge whether or not the following is a good hash function:</p>
<pre class='prettyprint'>
  unsigned int hash (string toHash) {
      unsigned int result = 0;
      for (int i = 0; i &lt; toHash.length(); i++) {
          result = result * 101 + toHash[i];
      }
      return result % MAX_BUCKETS;
  }
</pre>
              <br/>
              <p>This last one isn't bad; it's deterministic, simple, and stays in the range of our max number of buckets.</p>
              <p class='question' name='hash-q1-1'>Why did I choose to multiply by 101? What is special about the number 101 (or numbers like it)?</p>
              <p class='answer' name='hash-q1-1'>
                It's prime! When we multiply by a prime number, the chances of getting a unique result are higher because of the lack of factors. This helps us distribute keys to our buckets.
              </p>
              <br/>
              <p>Alright, so let's add that to our HashTable!</p>
              <p>We'll make it private because for this example, only our HashTable functions will care about the hash.</p>
<pre class='prettyprint'>
  template &lt;typename T&gt;
  class HashTable {
      private:
          int MAX_BUCKETS;
          vector&lt;list&lt;T&gt;&gt; buckets;
  
          // NOTE: If we want to be able to handle other
          // template types than strings for T, we'd need
          // other, more generalized hash functions...
          unsigned int hash (string toHash) {
              unsigned int result = 0;
              for (int i = 0; i &lt; toHash.length(); i++) {
                  result = result * 101 + toHash[i];
              }
              return result % MAX_BUCKETS;
          }
  
      public:
          HashTable (): MAX_BUCKETS(1000) {
              // Start off the buckets with MAX_BUCKETS
              buckets.resize(MAX_BUCKETS);
          }
  };
</pre>
              <br/>
              <p>It's coming along!</p>
              <p>Let's examine inserting items into our HashTable.</p>
              
              <br/>
              <h3>HashTable Insertion</h3>
              <p>So now that we have our hash function and our buckets with their lists, let's define our insertion behavior.</p>
              <p class='example'>Complete the HashTable's insertion function below:</p>
<pre class='prettyprint'>
  void insert (T toInsert) {
    // [!] Push toInsert to the back of the list that the
    // hash function gives you from input toInsert
    buckets[ ??? ].push_back(toInsert);
  }
</pre>
              <br/>
              <p class='debug'>Warning! The above insert function is missing something? What is it?</p>
              <p>OK we'll deal with that in a moment...</p>
              <p>I'll provide you with a neat print function just to display some syntactic sugaring for a printout:</p>
<pre class='prettyprint'>
  void print () {
      for (int i = 0; i &lt; buckets.size(); i++) {
          list&lt;T&gt;::iterator it = buckets[i].begin();
          if (buckets[i].empty()) {
              continue;
          }
          cout &lt;&lt; "=== Bucket[ " &lt;&lt; i &lt;&lt; " ] ===" &lt;&lt; endl;
          while (it != buckets[i].end()) {
              cout &lt;&lt; *it++ &lt;&lt; endl;
          }
      }
  }
</pre>
              <br/>
              <p>OK, so now we have the following HashTable class and a nice little test script:</p>
<pre class='prettyprint'>
  template &lt;typename T&gt;
  class HashTable {
      private:
          int MAX_BUCKETS;
          vector&lt;list&lt;T&gt;&gt; buckets;
  
          unsigned int hash (string toHash) {
              unsigned int result = 0;
              for (int i = 0; i &lt; toHash.length(); i++) {
                  result = result * 101 + toHash[i];
              }
              return result % MAX_BUCKETS;
          }
  
      public:
          HashTable (): MAX_BUCKETS(1000) {
              buckets.resize(MAX_BUCKETS);
          }
          void insert (T toInsert) {
              buckets[HashTable::hash(toInsert)].push_back(toInsert);
          }
          void print () {
              for (int i = 0; i &lt; buckets.size(); i++) {
                  typename list&lt;T&gt;::iterator it = buckets[i].begin();
                  if (buckets[i].empty()) {
                      continue;
                  }
                  cout &lt;&lt; "=== Bucket[ " &lt;&lt; i &lt;&lt; " ] ===" &lt;&lt; endl;
                  while (it != buckets[i].end()) {
                      cout &lt;&lt; *it++ &lt;&lt; endl;
                  }
              }
          }
  };
  
  int main () {
      HashTable&lt;string&gt; hashy;
      hashy.insert("To");
      hashy.insert("Hash");
      hashy.insert("Or");
      hashy.insert("Not");
      hashy.insert("To");
      hashy.insert("Hash");
      hashy.print();
  }
</pre>
              <br/>
              <p>
                Now, the issue with our insert is that it currently allows for duplicate keys... we can't have this behavior in a hash table because it would be ambiguous to talk about a key (which is
                meant to be unique) when there are multiple instances of that key.
              </p>
              <p>Let's implement our hasKey function below:</p>
              <p class='debug'>
                NOTE: If we were really designing a HashTable class, we'd probably want to implement a HashTable iterator, but since this is an intro example, we'll reduce the find functionality
                to just a boolean return function.
              </p>
<pre class='prettyprint'>
  bool hasKey (T query) {
      // Store a pointer to the bucket's list
      list&lt;T&gt;* lPtr = &amp;buckets[hash(query)];
      // Start an iterator at it's beginning
      list&lt;T&gt;::iterator it = lPtr-&gt;begin();
      // Search linearly for the query item
      while (it != lPtr-&gt;end()) {
          if (*it == query) {
              break;
          }
          it++;
      }
      // Return whether the iterator found a
      // match or not
      return it != lPtr-&gt;end();
  }
</pre>
              <p>Now, we can fix our insertion function to not add duplicates!</p>
<pre class='prettyprint'>
  void insert (T toInsert) {
      if (hasKey(toInsert)) {
          return;
      }
      buckets[HashTable::hash(toInsert)].push_back(toInsert);
  }
</pre>
              <p>Now if we run our previous test main function, we see that duplicate keys are not added, just as we'd like. Cool!</p>
              
              <br/>
              <h3>Hash Table Complexities</h3>
              <p>So it might be clear how we're able to find a bucket in constant time (random access of vector + hash function), but why is searching the bucket list considered average case constant?</p>
              <p>Well let's look at a certain property of hash tables:</p>
              <p class='definition'>The <strong>load factor</strong> of a hash table is the ratio of the number of items stored in total divided by the number of buckets.</p>
              <br/>
              <p>So, the lower the load factor, and assuming our hash function is doing a good job of evenly distributing keys across buckets, the faster our lookup in each list is going to be!</p>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/winter-2014/cs-32/week-10/hash-1.png' />
              </div>
              <hr/>
              <p>We see that a hash table with a ton of items and few buckets will have a large load factor and nearing linear lookup and insertion time.</p>
              <div class='text-center fit-pres'>
                <img src='../../../assets/images/winter-2014/cs-32/week-10/hash-2.png' />
              </div>
              <p>The solution that modern hash tables use: create more buckets whenever the load factor gets too high!</p>
              <p>Assuming that our hash function is uniformly distributing keys, this puts a *constant upper bound* on the number of items in any given bucket list. Thus the O(1).</p>
              
              <br/>
              <h3>Hash Table Sorting</h3>
              <p>With binary search trees, obtaining a sorted list of the items was trivial: an inorder traversal...</p>
              <p>With hash tables, we don't have the same luxury of structure since our hash function threw keys all over the place.</p>
              <p class='definition'>With hash tables, our concern is less about sorting values than it is about quickly storing and looking them up...</p>
              <br/>
              <p>Just like STL lists don't have a find function because it's a rather wonky operation taking O(n), so is a sort operation somewhat auxiliary to the hash table purpose.</p>
              <p>So what's a viable work-around for implementing a hash table sort?</p>
              <p class='question' name='hash-q2'>Assume we have iterators for our hash tables... how might we use these to sort our keys?</p>
              <p class='answer' name='hash-q2'>
                You could, upon a sort function call, simply create some other data structure (like a BST) comprised of pointers to the values in the hash table, which could then give a nice
                ordering for the values currently in the hash table.
              </p>
              
              <br/>
              <h3>#include &lt;unordered_set&gt;</h3>
              <p>The STL version of a hash table is an unordered_set. You can use it in the following way:</p>
<pre class='prettyprint'>
  int main () {
      unordered_set&lt;int&gt; ui;
      
      // You can insert keys
      ui.insert(1);
      ui.insert(17);
      ui.insert(12);
      ui.insert(20);
  
      // You can define iterators and look for values
      unordered_set&lt;int&gt;::iterator it = ui.find(1);
  
      // [!] WARNING: Will the following necessarily print
      // out 1, 12, 17, 20 in order?
      it = ui.begin();
      while (it != ui.end()) {
          cout &lt;&lt; *it++ &lt;&lt; endl;
      }
  
      // You can even print out how many buckets it has!
      cout &lt;&lt; "Buckets: " &lt;&lt; ui.bucket_count() &lt;&lt; endl;
  
      // And the load factor!
      cout &lt;&lt; "Load factor: " &lt;&lt; ui.load_factor() &lt;&lt; endl;
  
      // And of course, clear it
      ui.clear();
  }
</pre>
              <br/>
              <p>So those are hash tables!</p>
            </div>
            <hr/>
            
            
            <a class='btn btn-default pull-right hidden-print' href='javascript:window.print();'>
              <span class='glyphicon glyphicon-print'></span>
              &nbsp; PDF / Print
            </a>
            
          </div>
          <!-- END PRESENTATION CONTENT -->
          
          <!-- MATERIALS FROM CLASS: -->
          
          
        </div>
      </div>
      <!-- END MAIN CONTENT -->
      
          
    </div>
    <!-- END WRAPPER -->
    
    <!-- BEGIN FOOTER -->
    <div id="footer">
      <div class="container">
        <div class="col-md-12 text-center">
          
        </div>
      </div>
    </div>
    <!-- END FOOTER -->
    
  </body>
</html>
